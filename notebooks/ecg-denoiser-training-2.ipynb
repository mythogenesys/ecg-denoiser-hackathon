{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mythogenesys/ecg-denoiser-hackathon/blob/main/notebooks/ecg-denoiser-training-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Upload the notebook you downloaded from Colab\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load and fix metadata\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# Remove only the widgets metadata if present\n",
        "if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "    del nb[\"metadata\"][\"widgets\"]\n",
        "    print(\"Removed 'metadata.widgets'\")\n",
        "\n",
        "# Step 3: Save fixed notebook\n",
        "fixed_filename = \"fixed_\" + filename\n",
        "with open(fixed_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"Saved cleaned notebook as\", fixed_filename)\n",
        "\n",
        "# Step 4: Download back to your computer\n",
        "files.download(fixed_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "piHeZkQXINfW",
        "outputId": "983e9042-4138-4d09-dec5-dac77be17fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0985cd84-4360-4339-9299-784e0bc0deb1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0985cd84-4360-4339-9299-784e0bc0deb1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICkwu8-o2UcQ",
        "outputId": "54740006-a70f-49ff-b7c5-ff93c2be3bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [Step 1/5] Setting up the environment ---\n",
            "Mounted at /content/drive\n",
            "\n",
            "Cloning repository from https://github.com/Mohan-CAS-and-hackathons/ecg-denoiser-hackathon.git...\n",
            "Cloning into 'ecg-denoiser-hackathon'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 164 (delta 49), reused 83 (delta 24), pack-reused 55 (from 1)\u001b[K\n",
            "Receiving objects: 100% (164/164), 87.49 MiB | 4.93 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "✅ Successfully changed directory to: /content/ecg-denoiser-hackathon\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "#      FINAL: Full ECG Denoising Ablation & Validation Study Notebook\n",
        "# ==============================================================================\n",
        "# This notebook consolidates all setup, environment fixes, code synchronization,\n",
        "# training, and validation into a single, runnable block.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Ensure your data is in Google Drive at:\n",
        "#    /content/drive/MyDrive/ecg_denoiser_hackathon/data/\n",
        "# 2. Run this entire cell.\n",
        "# 3. The process will take a significant amount of time (1-2 hours depending on\n",
        "#    the number of epochs).\n",
        "# 4. Final results (trained models and confusion matrices) will be saved back\n",
        "#    to your Google Drive.\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "# ---\n",
        "# CELL 1: SETUP - Mount Drive & Clone Repository\n",
        "# ---\n",
        "print(\"--- [Step 1/5] Setting up the environment ---\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Your specific GitHub repository and project folder name\n",
        "GIT_REPO = \"ecg-denoiser-hackathon\"\n",
        "GIT_PATH = f\"https://github.com/Mohan-CAS-and-hackathons/{GIT_REPO}.git\"\n",
        "\n",
        "if not os.path.exists(GIT_REPO):\n",
        "    print(f\"\\nCloning repository from {GIT_PATH}...\")\n",
        "    !git clone {GIT_PATH}\n",
        "else:\n",
        "    print(f\"\\nRepository '{GIT_REPO}' already exists. Skipping clone.\")\n",
        "\n",
        "# CRITICAL: Change directory into the repository for all subsequent commands\n",
        "os.chdir(GIT_REPO)\n",
        "print(f\"✅ Successfully changed directory to: {os.getcwd()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj7Er-aX2kxp",
        "outputId": "c807b6ff-8e7a-4c4a-f264-952f7a31addd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ecg-denoiser-hackathon\n",
            "all_beats.npy\tdocs\t   requirements.txt   src\n",
            "all_labels.npy\tmodels\t   RESEARCH_PAPER.md  STPC_research_paper.md\n",
            "app.py\t\tnotebooks  results\t      triangular_pulse_appendix.md\n",
            "assets\t\tREADME.md  samples\t      tutorials\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# CELL 2: CODE SYNC & ENVIRONMENT CORRECTION\n",
        "# ---\n",
        "print(\"\\n--- [Step 2/5] Synchronizing source code and fixing environment ---\")\n",
        "\n",
        "# --- Part A: Overwrite all src files with your final, correct versions ---\n",
        "print(\"Overwriting local files with your provided source code...\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IweMYJ-L2d4P",
        "outputId": "59f38b2a-1625-4ed4-b78b-6f8585a0c65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [Step 2/5] Synchronizing source code and fixing environment ---\n",
            "Overwriting local files with your provided source code...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Part B: Install dependencies and upgrade wfdb ---\n",
        "print(\"\\nInstalling dependencies and upgrading wfdb...\")\n",
        "!pip install -r requirements.txt\n",
        "!pip uninstall -y wfdb\n",
        "!pip install --upgrade wfdb\n",
        "\n",
        "print(\"\\n\\n✅✅✅ Environment is fully prepared. Proceeding to training. ✅✅✅\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO3SGed72tp1",
        "outputId": "84ec0527-cba1-43ae-a817-d6d51eb72347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installing dependencies and upgrading wfdb...\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.16.1)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
            "Collecting wfdb (from -r requirements.txt (line 13))\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting streamlit (from -r requirements.txt (line 16))\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (1.6.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.3)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb->-r requirements.txt (line 13)) (3.12.15)\n",
            "INFO: pip is looking at multiple versions of wfdb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting wfdb (from -r requirements.txt (line 13))\n",
            "  Downloading wfdb-4.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb->-r requirements.txt (line 13)) (0.13.1)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb->-r requirements.txt (line 13)) (2.32.4)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (8.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 16))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r requirements.txt (line 16)) (6.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 18)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 18)) (3.6.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 16)) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 16)) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 16)) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 13)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 13)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 13)) (2025.8.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from SoundFile>=0.10.0->wfdb->-r requirements.txt (line 13)) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->-r requirements.txt (line 13)) (2.23)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 16)) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 16)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 16)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 16)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requirements.txt (line 16)) (0.27.1)\n",
            "Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, wfdb, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1 wfdb-4.1.2\n",
            "Found existing installation: wfdb 4.1.2\n",
            "Uninstalling wfdb-4.1.2:\n",
            "  Successfully uninstalled wfdb-4.1.2\n",
            "Collecting wfdb\n",
            "  Using cached wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.1)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.8.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, wfdb\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.2 wfdb-4.3.0\n",
            "\n",
            "\n",
            "✅✅✅ Environment is fully prepared. Proceeding to training. ✅✅✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# CELL 3: TRAINING - Run the Ablation Study\n",
        "# ---\n",
        "# NOTE: You can edit src/train.py and change NUM_EPOCHS to a smaller number (e.g., 20)\n",
        "# to make this process faster for testing.\n",
        "\n",
        "print(\"\\n--- [Step 3/5] Starting Ablation Study Training ---\")\n",
        "\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/ecg_denoiser_hackathon/'\n",
        "MODEL_DIR = os.path.join(DRIVE_BASE_PATH, 'models')\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "MODEL_PATH_L1_ONLY = os.path.join(MODEL_DIR, 'denoiser_l1_only.pth')\n",
        "MODEL_PATH_L1_GRAD = os.path.join(MODEL_DIR, 'denoiser_l1_grad.pth')\n",
        "MODEL_PATH_STPC_FULL = os.path.join(MODEL_DIR, 'denoiser_stpc_full.pth')\n",
        "\n",
        "print(\"\\n--- [Run 1/3] Training Model with L1 Loss Only ---\")\n",
        "!python3 src/train.py \\\n",
        "    --model_save_path \"{MODEL_PATH_L1_ONLY}\" \\\n",
        "    --no-gradient-loss \\\n",
        "    --no-fft-loss\n",
        "\n",
        "print(\"\\n--- [Run 2/3] Training Model with L1 + Gradient Loss ---\")\n",
        "!python3 src/train.py \\\n",
        "    --model_save_path \"{MODEL_PATH_L1_GRAD}\" \\\n",
        "    --no-fft-loss\n",
        "\n",
        "print(\"\\n--- [Run 3/3] Training Model with Full STPC Loss ---\")\n",
        "!python3 src/train.py \\\n",
        "    --model_save_path \"{MODEL_PATH_STPC_FULL}\"\n",
        "\n",
        "print(\"\\n✅ Ablation study training complete!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K_dqhan29Gp",
        "outputId": "9ac80805-b8f2-49b0-e92d-1eac03af6d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [Step 3/5] Starting Ablation Study Training ---\n",
            "\n",
            "--- [Run 1/3] Training Model with L1 Loss Only ---\n",
            "Using device: cuda\n",
            "Gradient Loss Enabled: False\n",
            "FFT Loss Enabled: False\n",
            "Model will be saved to: /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            "Initializing dataset: loading all clean record names...\n",
            "Loading all noise signals into memory...\n",
            "Loading all clean signals into memory for faster access...\n",
            "100% 48/48 [00:20<00:00,  2.30it/s]\n",
            "Dataset initialized with 48 usable clean signals.\n",
            "/content/ecg-denoiser-hackathon/src/train.py:195: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "  0% 0/313 [00:00<?, ?it/s]/content/ecg-denoiser-hackathon/src/train.py:138: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "100% 313/313 [00:19<00:00, 15.98it/s, loss=0.13]\n",
            "Epoch 1/50, Average Loss: 0.201804\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            "100% 313/313 [00:18<00:00, 17.11it/s, loss=0.158]\n",
            "Epoch 2/50, Average Loss: 0.156606\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            "100% 313/313 [00:18<00:00, 17.00it/s, loss=0.13]\n",
            "Epoch 3/50, Average Loss: 0.144887\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            "100% 313/313 [00:18<00:00, 16.91it/s, loss=0.128]\n",
            "Epoch 4/50, Average Loss: 0.137031\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            "100% 313/313 [00:18<00:00, 16.61it/s, loss=0.16]\n",
            "Epoch 5/50, Average Loss: 0.133850\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            " 20% 64/313 [00:03<00:14, 16.66it/s, loss=0.159]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 235, in <module>\n",
            "    main(cli_args)\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 198, in main\n",
            "    avg_loss = train_one_epoch(\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 139, in train_one_epoch\n",
            "    denoised = model(noisy)\n",
            "               ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ecg-denoiser-hackathon/src/model.py\", line 81, in forward\n",
            "    x = self.decoder[i + 1](concat_skip)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ecg-denoiser-hackathon/src/model.py\", line 22, in forward\n",
            "    return self.conv(x)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 244, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py\", line 135, in forward\n",
            "    return F.relu(input, inplace=self.inplace)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 1699, in relu\n",
            "    result = torch.relu_(input)\n",
            "             ^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "--- [Run 2/3] Training Model with L1 + Gradient Loss ---\n",
            "Using device: cuda\n",
            "Gradient Loss Enabled: True\n",
            "FFT Loss Enabled: False\n",
            "Model will be saved to: /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            "Initializing dataset: loading all clean record names...\n",
            "Loading all noise signals into memory...\n",
            "Loading all clean signals into memory for faster access...\n",
            "100% 48/48 [00:03<00:00, 15.00it/s]\n",
            "Dataset initialized with 48 usable clean signals.\n",
            "/content/ecg-denoiser-hackathon/src/train.py:195: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "  0% 0/313 [00:00<?, ?it/s]/content/ecg-denoiser-hackathon/src/train.py:138: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "100% 313/313 [00:19<00:00, 16.37it/s, loss=0.149]\n",
            "Epoch 1/50, Average Loss: 0.201110\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            "100% 313/313 [00:18<00:00, 16.69it/s, loss=0.133]\n",
            "Epoch 2/50, Average Loss: 0.160030\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            "100% 313/313 [00:18<00:00, 16.61it/s, loss=0.18]\n",
            "Epoch 3/50, Average Loss: 0.151090\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            "100% 313/313 [00:18<00:00, 16.89it/s, loss=0.128]\n",
            "Epoch 4/50, Average Loss: 0.144927\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            "100% 313/313 [00:18<00:00, 16.81it/s, loss=0.131]\n",
            "Epoch 5/50, Average Loss: 0.139328\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            " 25% 79/313 [00:04<00:14, 16.40it/s, loss=0.123]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 235, in <module>\n",
            "    main(cli_args)\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 198, in main\n",
            "    avg_loss = train_one_epoch(\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 159, in train_one_epoch\n",
            "    scaler.step(optimizer)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 465, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 359, in _maybe_opt_step\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 359, in <genexpr>\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "               ^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "--- [Run 3/3] Training Model with Full STPC Loss ---\n",
            "Using device: cuda\n",
            "Gradient Loss Enabled: True\n",
            "FFT Loss Enabled: True\n",
            "Model will be saved to: /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            "Initializing dataset: loading all clean record names...\n",
            "Loading all noise signals into memory...\n",
            "Loading all clean signals into memory for faster access...\n",
            "100% 48/48 [00:05<00:00,  9.43it/s]\n",
            "Dataset initialized with 48 usable clean signals.\n",
            "/content/ecg-denoiser-hackathon/src/train.py:195: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "  0% 0/313 [00:00<?, ?it/s]/content/ecg-denoiser-hackathon/src/train.py:138: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "/content/ecg-denoiser-hackathon/src/train.py:72: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at /pytorch/aten/src/ATen/EmptyTensor.cpp:55.)\n",
            "  pred_fft = torch.fft.fft(prediction, dim=-1)\n",
            "100% 313/313 [00:20<00:00, 15.31it/s, loss=0.636]\n",
            "Epoch 1/50, Average Loss: 0.952317\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            "100% 313/313 [00:19<00:00, 16.43it/s, loss=0.823]\n",
            "Epoch 2/50, Average Loss: 0.623486\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            "100% 313/313 [00:18<00:00, 16.81it/s, loss=0.555]\n",
            "Epoch 3/50, Average Loss: 0.581995\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            "100% 313/313 [00:18<00:00, 16.78it/s, loss=0.498]\n",
            "Epoch 4/50, Average Loss: 0.551416\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            "100% 313/313 [00:18<00:00, 16.95it/s, loss=0.471]\n",
            "Epoch 5/50, Average Loss: 0.524541\n",
            "Model saved to /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            " 35% 109/313 [00:06<00:11, 17.09it/s, loss=0.543]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a73b80df060>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1609, in _shutdown_workers\n",
            "    self._worker_result_queue.put((None, None))\n",
            "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 94, in put\n",
            "    self._start_thread()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 192, in _start_thread\n",
            "    self._thread.start()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 999, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 655, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 355, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt: \n",
            " 35% 110/313 [00:06<00:12, 16.54it/s, loss=0.543]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 235, in <module>\n",
            "    main(cli_args)\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 198, in main\n",
            "    avg_loss = train_one_epoch(\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ecg-denoiser-hackathon/src/train.py\", line 139, in train_one_epoch\n",
            "    denoised = model(noisy)\n",
            "               ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ecg-denoiser-hackathon/src/model.py\", line 60, in forward\n",
            "    x = self.pool(x)\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/pooling.py\", line 145, in forward\n",
            "    return F.max_pool1d(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_jit_internal.py\", line 627, in fn\n",
            "    return if_false(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 737, in _max_pool1d\n",
            "    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "✅ Ablation study training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# CELL 4: VALIDATION - Run End-to-End Validation for the Ablation Study\n",
        "# ---\n",
        "print(\"\\n--- [Step 4/5] Starting End-to-End Validation for All Models ---\")\n",
        "\n",
        "RESULTS_DIR = os.path.join(DRIVE_BASE_PATH, 'results')\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "OUTPUT_PREFIX_L1_ONLY = os.path.join(RESULTS_DIR, 'l1_only')\n",
        "OUTPUT_PREFIX_L1_GRAD = os.path.join(RESULTS_DIR, 'l1_grad')\n",
        "OUTPUT_PREFIX_STPC_FULL = os.path.join(RESULTS_DIR, 'stpc_full')\n",
        "\n",
        "print(\"\\n--- [Run 1/3] Validating Model with L1 Loss Only ---\")\n",
        "!python3 src/validate_end_to_end.py \\\n",
        "    --denoiser_model_path \"{MODEL_PATH_L1_ONLY}\" \\\n",
        "    --output_prefix \"{OUTPUT_PREFIX_L1_ONLY}\"\n",
        "\n",
        "print(\"\\n--- [Run 2/3] Validating Model with L1 + Gradient Loss ---\")\n",
        "!python3 src/validate_end_to_end.py \\\n",
        "    --denoiser_model_path \"{MODEL_PATH_L1_GRAD}\" \\\n",
        "    --output_prefix \"{OUTPUT_PREFIX_L1_GRAD}\"\n",
        "\n",
        "print(\"\\n--- [Run 3/3] Validating Model with Full STPC Loss ---\")\n",
        "!python3 src/validate_end_to_end.py \\\n",
        "    --denoiser_model_path \"{MODEL_PATH_STPC_FULL}\" \\\n",
        "    --output_prefix \"{OUTPUT_PREFIX_STPC_FULL}\"\n",
        "\n",
        "print(\"\\n\\n✅✅✅ Ablation study validation complete! ✅✅✅\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# CELL 5: FINAL CHECK - Verify Output Files\n",
        "# ---\n",
        "print(\"\\n--- [Step 5/5] Verifying output files in Google Drive ---\")\n",
        "print(\"\\nTrained Models:\")\n",
        "!ls -lh {MODEL_DIR}\n",
        "\n",
        "print(\"\\nValidation Results (Confusion Matrices):\")\n",
        "!ls -lh {RESULTS_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wbFMvzd2_yC",
        "outputId": "a345cc69-e95d-4107-c64c-6fbc6667d4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [Step 4/5] Starting End-to-End Validation for All Models ---\n",
            "\n",
            "--- [Run 1/3] Validating Model with L1 Loss Only ---\n",
            "--- Starting End-to-End Validation ---\n",
            "Using Device: cuda\n",
            "Test Record: 201, Noise Level: 0 dB SNR\n",
            "Loading Denoiser from: /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_only.pth\n",
            "Output file prefix: /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_only\n",
            "Loading models...\n",
            "Downloading fresh copy of record '201' from PhysioNet to bypass local read errors...\n",
            "Generating record list for: 201\n",
            "Generating list of all files for: 201\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Download complete.\n",
            "Synthesizing a highly noisy signal...\n",
            "Available noise types: dict_keys(['baseline_wander', 'electrode_motion', 'muscle_artifact'])\n",
            "Using 'baseline_wander' noise for validation.\n",
            "Denoising the signal with the U-Net model...\n",
            "Classifying beats from all three signal types...\n",
            "\n",
            "--- PERFORMANCE ON NOISY SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.96      1.00      0.98      1635\n",
            "           L       0.92      0.48      0.63       128\n",
            "           R       0.97      0.96      0.97       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96      1963\n",
            "   macro avg       0.18      0.15      0.16      1963\n",
            "weighted avg       0.96      0.96      0.95      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_only_confusion_matrix_noisy.png\n",
            "\n",
            "--- PERFORMANCE ON DENOISED SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.97      1.00      0.98      1635\n",
            "           L       0.97      0.59      0.73       128\n",
            "           R       0.98      0.99      0.98       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97      1963\n",
            "   macro avg       0.18      0.16      0.17      1963\n",
            "weighted avg       0.97      0.97      0.97      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_only_confusion_matrix_denoised.png\n",
            "\n",
            "--- PERFORMANCE ON CLEAN SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.97      1.00      0.99      1635\n",
            "           L       0.98      0.68      0.80       128\n",
            "           R       1.00      0.99      1.00       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98      1963\n",
            "   macro avg       0.18      0.17      0.17      1963\n",
            "weighted avg       0.98      0.98      0.97      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_only_confusion_matrix_clean.png\n",
            "\n",
            "✅ Validation complete. Check the classification reports and saved plots.\n",
            "\n",
            "--- [Run 2/3] Validating Model with L1 + Gradient Loss ---\n",
            "--- Starting End-to-End Validation ---\n",
            "Using Device: cuda\n",
            "Test Record: 201, Noise Level: 0 dB SNR\n",
            "Loading Denoiser from: /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_l1_grad.pth\n",
            "Output file prefix: /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_grad\n",
            "Loading models...\n",
            "Downloading fresh copy of record '201' from PhysioNet to bypass local read errors...\n",
            "Generating record list for: 201\n",
            "Generating list of all files for: 201\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Download complete.\n",
            "Synthesizing a highly noisy signal...\n",
            "Available noise types: dict_keys(['baseline_wander', 'electrode_motion', 'muscle_artifact'])\n",
            "Using 'baseline_wander' noise for validation.\n",
            "Denoising the signal with the U-Net model...\n",
            "Classifying beats from all three signal types...\n",
            "\n",
            "--- PERFORMANCE ON NOISY SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.96      1.00      0.98      1635\n",
            "           L       0.92      0.48      0.63       128\n",
            "           R       0.97      0.96      0.97       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96      1963\n",
            "   macro avg       0.18      0.15      0.16      1963\n",
            "weighted avg       0.96      0.96      0.95      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_grad_confusion_matrix_noisy.png\n",
            "\n",
            "--- PERFORMANCE ON DENOISED SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.97      1.00      0.98      1635\n",
            "           L       0.95      0.57      0.71       128\n",
            "           R       0.98      0.99      0.98       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97      1963\n",
            "   macro avg       0.18      0.16      0.17      1963\n",
            "weighted avg       0.97      0.97      0.96      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_grad_confusion_matrix_denoised.png\n",
            "\n",
            "--- PERFORMANCE ON CLEAN SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.97      1.00      0.99      1635\n",
            "           L       0.98      0.68      0.80       128\n",
            "           R       1.00      0.99      1.00       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98      1963\n",
            "   macro avg       0.18      0.17      0.17      1963\n",
            "weighted avg       0.98      0.98      0.97      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/l1_grad_confusion_matrix_clean.png\n",
            "\n",
            "✅ Validation complete. Check the classification reports and saved plots.\n",
            "\n",
            "--- [Run 3/3] Validating Model with Full STPC Loss ---\n",
            "--- Starting End-to-End Validation ---\n",
            "Using Device: cuda\n",
            "Test Record: 201, Noise Level: 0 dB SNR\n",
            "Loading Denoiser from: /content/drive/MyDrive/ecg_denoiser_hackathon/models/denoiser_stpc_full.pth\n",
            "Output file prefix: /content/drive/MyDrive/ecg_denoiser_hackathon/results/stpc_full\n",
            "Loading models...\n",
            "Downloading fresh copy of record '201' from PhysioNet to bypass local read errors...\n",
            "Generating record list for: 201\n",
            "Generating list of all files for: 201\n",
            "Downloading files...\n",
            "Finished downloading files\n",
            "Download complete.\n",
            "Synthesizing a highly noisy signal...\n",
            "Available noise types: dict_keys(['baseline_wander', 'electrode_motion', 'muscle_artifact'])\n",
            "Using 'baseline_wander' noise for validation.\n",
            "Denoising the signal with the U-Net model...\n",
            "Classifying beats from all three signal types...\n",
            "\n",
            "--- PERFORMANCE ON NOISY SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.96      1.00      0.98      1635\n",
            "           L       0.92      0.48      0.63       128\n",
            "           R       0.97      0.96      0.97       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96      1963\n",
            "   macro avg       0.18      0.15      0.16      1963\n",
            "weighted avg       0.96      0.96      0.95      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/stpc_full_confusion_matrix_noisy.png\n",
            "\n",
            "--- PERFORMANCE ON DENOISED SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.97      1.00      0.98      1635\n",
            "           L       0.97      0.59      0.74       128\n",
            "           R       0.99      1.00      0.99       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97      1963\n",
            "   macro avg       0.18      0.16      0.17      1963\n",
            "weighted avg       0.97      0.97      0.97      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/stpc_full_confusion_matrix_denoised.png\n",
            "\n",
            "--- PERFORMANCE ON CLEAN SIGNAL ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.97      1.00      0.99      1635\n",
            "           L       0.98      0.68      0.80       128\n",
            "           R       1.00      0.99      1.00       198\n",
            "           e       0.00      0.00      0.00         2\n",
            "           j       0.00      0.00      0.00         0\n",
            "           A       0.00      0.00      0.00         0\n",
            "           a       0.00      0.00      0.00         0\n",
            "           J       0.00      0.00      0.00         0\n",
            "           S       0.00      0.00      0.00         0\n",
            "           V       0.00      0.00      0.00         0\n",
            "           E       0.00      0.00      0.00         0\n",
            "           F       0.00      0.00      0.00         0\n",
            "           Q       0.00      0.00      0.00         0\n",
            "           ?       0.00      0.00      0.00         0\n",
            "           |       0.00      0.00      0.00         0\n",
            "           /       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98      1963\n",
            "   macro avg       0.18      0.17      0.17      1963\n",
            "weighted avg       0.98      0.98      0.97      1963\n",
            "\n",
            "Saved confusion matrix to /content/drive/MyDrive/ecg_denoiser_hackathon/results/stpc_full_confusion_matrix_clean.png\n",
            "\n",
            "✅ Validation complete. Check the classification reports and saved plots.\n",
            "\n",
            "\n",
            "✅✅✅ Ablation study validation complete! ✅✅✅\n",
            "\n",
            "--- [Step 5/5] Verifying output files in Google Drive ---\n",
            "\n",
            "Trained Models:\n",
            "total 126M\n",
            "-rw------- 1 root root  42M Sep 22 10:02 denoiser_l1_grad.pth\n",
            "-rw------- 1 root root  42M Sep 22 10:00 denoiser_l1_only.pth\n",
            "-rw------- 1 root root  42M Sep 22 10:04 denoiser_stpc_full.pth\n",
            "-rw------- 1 root root 1.1M Sep 21 01:46 ecg_classifier_model.pth\n",
            "\n",
            "Validation Results (Confusion Matrices):\n",
            "total 296K\n",
            "-rw------- 1 root root 32K Sep 22 10:07 l1_grad_confusion_matrix_clean.png\n",
            "-rw------- 1 root root 34K Sep 22 10:07 l1_grad_confusion_matrix_denoised.png\n",
            "-rw------- 1 root root 33K Sep 22 10:07 l1_grad_confusion_matrix_noisy.png\n",
            "-rw------- 1 root root 32K Sep 22 10:07 l1_only_confusion_matrix_clean.png\n",
            "-rw------- 1 root root 34K Sep 22 10:07 l1_only_confusion_matrix_denoised.png\n",
            "-rw------- 1 root root 33K Sep 22 10:07 l1_only_confusion_matrix_noisy.png\n",
            "-rw------- 1 root root 32K Sep 22 10:08 stpc_full_confusion_matrix_clean.png\n",
            "-rw------- 1 root root 34K Sep 22 10:08 stpc_full_confusion_matrix_denoised.png\n",
            "-rw------- 1 root root 33K Sep 22 10:08 stpc_full_confusion_matrix_noisy.png\n"
          ]
        }
      ]
    }
  ]
}